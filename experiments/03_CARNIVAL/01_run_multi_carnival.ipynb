{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a57338fc-3dc3-462d-90b0-e56cc49a29d5",
   "metadata": {},
   "source": [
    "# Multi CARNIVAL on PANACEA\n",
    "\n",
    "This notebook shows how the results can be generated. To generate the results for the manuscript, we used the `script.py` in a HPC for convenience. Multi-condition methods require a high performance MILP solver. We used GUROBI for all experiments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39495b2b-8436-422b-ad74-57acab992e4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import corneto as cn\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "cn.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "405899e0-4cab-4c86-8b38-f31a21e857d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_drug = \"PONATINIB\"\n",
    "selected_cells = [\"H1793\", \"LNCAP\", \"KRJ1\", \"HCC1143\", \"EFO21\", \"PANC1\", \"HF2597\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73f733f3-a0e5-4e26-b511-c913b3568b85",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_panacea = pd.read_csv(\"GSE186341-PANACEA.tsv.xz\", sep='\\t')\n",
    "df_panacea['drug'] = df_panacea['obs_id'].str.extract(r'_(.*?)_v')\n",
    "df_panacea['cell'] = df_panacea['obs_id'].str.extract( r'^([^_]*)')\n",
    "df_panacea['sign'] = np.sign(df_panacea['act'])\n",
    "df_panacea"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73e03405-f605-4b78-8da4-114884e5b56e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_df(\n",
    "    cells,\n",
    "    drugs,\n",
    "    df = df_panacea, \n",
    "    resource = \"dorothea\", \n",
    "    pipeline = \"NA+deseq2\", \n",
    "    statparam = \"stat\", \n",
    "    status = \"unfiltered\", \n",
    "    padj = 0.05\n",
    "):\n",
    "    c = [c.upper() for c in cells]\n",
    "    d = [d.upper() for d in drugs]\n",
    "    dff = df[\n",
    "        (df.cell.str.upper().isin(c)) & \n",
    "        (df.drug.str.upper().isin(d)) & \n",
    "        (df.resource == resource) & \n",
    "        (df.pipeline == pipeline) &\n",
    "        (df.statparam == statparam) &\n",
    "        (df.status == status) &\n",
    "        (df.padj <= padj)\n",
    "    ]\n",
    "    return dff\n",
    "\n",
    "df_conditions = filter_df(selected_cells, [selected_drug])\n",
    "df_conditions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ae11c91-cb33-4d3f-9d64-f5ad93c57f3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_measurements(cell, drug, df = df_panacea, resource = \"dorothea\", pipeline = \"NA+deseq2\", statparam = \"stat\", padj = 0.05, as_dict=True):\n",
    "    df_r = df[\n",
    "        (df.drug.str.upper() == drug.upper()) & \n",
    "        (df.cell.str.upper() == cell.upper()) & \n",
    "        (df.resource == resource) & \n",
    "        (df.pipeline == pipeline) &\n",
    "        (df.statparam == statparam) &\n",
    "        (df.padj <= padj)\n",
    "    ]\n",
    "    if as_dict:\n",
    "        return df_r[[\"items\", \"sign\"]].set_index(\"items\").to_dict()[\"sign\"]\n",
    "    return df_r\n",
    "\n",
    "get_measurements(selected_cells[0], selected_drug)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e980c6d-6f8d-4525-a67e-1701f8041fd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "G_pkn = cn.Graph.from_sif(\"network_collectri.sif\", has_header=True, column_order=[0, 2, 1])\n",
    "G_pkn.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1951474e-cf8c-4e11-8774-ab930199f474",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drug bank PONATINIB interactions\n",
    "#BCR, ABL, VEGFR, PDGFR, FGFR, EPH receptors and SRC families of kinases, and KIT, RET, TIE2, and FLT3\n",
    "ponatinib_targets = [\"BCR\", \"ABL\", \"VEGFR\", \"PDGFRA_PDGFRB\", \"FGFR1\", \"FGFR2\", \"FGFR3\", \"FGFR4\", \"EPH\", \"SRC\", \"KIT\", \"RET\", \"TIE2\", \"FLT3\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3895d87-a987-4ff6-9b5f-090d9e3029d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "targets = {v: -1 for v in G_pkn.V if v in ponatinib_targets}\n",
    "targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "999a45c7-57bf-4ece-989a-77f18386958b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from corneto.methods.carnival import milp_carnival\n",
    "from corneto.methods.carnival import preprocess_graph, milp_carnival\n",
    "from corneto.methods.signaling import create_flow_graph, signflow\n",
    "from corneto.methods.carnival import runCARNIVAL_AcyclicFlow, runCARNIVAL_Flow_Acyclic, create_flow_carnival, create_flow_carnival_v2, create_flow_carnival_v3, create_flow_carnival_v4\n",
    "from corneto.methods import expand_graph_for_flows\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f82a9a12-7efd-4dad-a736-b53620407f2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def postprocess(G, edge_var, inputs, outputs):\n",
    "    sel_edges = set(np.flatnonzero(np.abs(edge_var) > 0))\n",
    "    exclude_edges = set()\n",
    "    G_edges = G.E\n",
    "    for eidx in sel_edges:\n",
    "        s, t = G_edges[eidx]\n",
    "        s = list(s)\n",
    "        t = list(t)\n",
    "        if len(s) == 0 or len(t) == 0 or s[0].startswith(\"_\") or t[0].startswith(\"_\"):\n",
    "            exclude_edges.add(eidx)\n",
    "    sel_edges = list(sel_edges.difference(exclude_edges))\n",
    "    G_sol = G.edge_subgraph(sel_edges)\n",
    "    sel_edges = set(sel_edges)\n",
    "    G_solp, p_inputs, p_outputs = preprocess_graph(G_sol, inputs, outputs)\n",
    "    return G_solp\n",
    "    \n",
    "def score(G, edge_var, vertex_var, inputs, outputs):\n",
    "    # Manual score a solution to avoid impl. specific differences\n",
    "    G_sol = postprocess(G, edge_var, inputs, outputs)\n",
    "    err_outputs = 0\n",
    "    Vsol = list(G_sol.V)\n",
    "    total = 0\n",
    "    V = list(G.V)\n",
    "    for k, v in outputs.items():\n",
    "        if k not in Vsol:\n",
    "            err_outputs += abs(v)\n",
    "        else:\n",
    "            err_outputs += abs(vertex_var[V.index(k)] - v)\n",
    "        total += abs(v)\n",
    "    return err_outputs/total, G_sol.shape[1]\n",
    "\n",
    "def prune(c_data, G_pkn):\n",
    "    all_inputs, all_outputs = set(), set()\n",
    "    for k, v in c_data.items():\n",
    "        for ki, (ti, vi) in v.items():\n",
    "            if isinstance(ki, str):\n",
    "                if ti == 'P':\n",
    "                    all_inputs.add(ki)\n",
    "                else:\n",
    "                    all_outputs.add(ki)\n",
    "            else:\n",
    "                print(ki, ti, vi)\n",
    "    \n",
    "    V = set(G_pkn.vertices)\n",
    "    c_inputs = V.intersection(all_inputs)\n",
    "    c_outputs = V.intersection(all_outputs)\n",
    "    print(f\"{len(c_inputs)}/{len(all_inputs)} inputs mapped to the graph\")\n",
    "    print(f\"{len(c_outputs)}/{len(all_outputs)} outputs mapped to the graph\")\n",
    "    print(f\"Pruning the graph with size: V x E = {G_pkn.shape}...\")\n",
    "    Gp = G_pkn.prune(list(c_inputs), list(c_outputs))\n",
    "    print(f\"Finished. Final size: V x E = {Gp.shape}.\")\n",
    "    return Gp, c_inputs, c_outputs\n",
    "\n",
    "def convert_input_dict(dataset):\n",
    "    conditions = dict()\n",
    "    for k, exp in dataset.items():\n",
    "        d_k = dict()\n",
    "        for inp, val in exp[\"input\"].items():\n",
    "            d_k[inp] = ('P', val)\n",
    "        for outp, val in exp[\"output\"].items():\n",
    "            d_k[outp] = ('M', val)\n",
    "        conditions[k] = d_k\n",
    "    return conditions\n",
    "\n",
    "def single_carnival(G, dataset, beta=0.25, max_time=600, norel=0, seed=0):\n",
    "    all_edges = np.zeros(G.shape[1])\n",
    "    selected_edges_per_sample = []\n",
    "    scores = []\n",
    "    E = list(G.E)\n",
    "    problems = []\n",
    "    for k, exp in dataset.items():\n",
    "        sol_edges = np.zeros(G.shape[1])\n",
    "        exp_inputs, exp_outputs = exp[\"input\"], exp[\"output\"]\n",
    "        Gp, cp_inputs, cp_outputs = preprocess_graph(G, exp_inputs, exp_outputs)\n",
    "        print(k, Gp.shape, len(cp_inputs), len(cp_outputs))\n",
    "        P = milp_carnival(Gp, cp_inputs, cp_outputs, beta_weight=beta)\n",
    "        P.solve(solver=\"GUROBI\", IntegralityFocus=1, TimeLimit=max_time, NoRelHeurTime=norel, Seed=seed, verbosity=0)\n",
    "        for o in P.objectives:\n",
    "            print(o.value)\n",
    "        s = score(Gp, P.expr.edge_values.value, P.expr.vertex_values.value, cp_inputs, cp_outputs)\n",
    "        scores.append(s)\n",
    "        problems.append(P)\n",
    "        # Select the edges\n",
    "        E_gp = Gp.E\n",
    "        sel_edges = np.flatnonzero(np.abs(P.expr.edge_values.value)>0)\n",
    "        sel_edges = [E_gp[idx] for idx in sel_edges]\n",
    "        for i, e in enumerate(E):\n",
    "            if e in sel_edges:\n",
    "                all_edges[i] += 1\n",
    "                sol_edges[i] = 1\n",
    "        selected_edges_per_sample.append(sol_edges)\n",
    "    return problems, scores, all_edges, selected_edges_per_sample\n",
    "\n",
    "\n",
    "def multi_carnival(G, dataset, lambd=0.25, norel=0, max_time=600, seed=0):\n",
    "    d = convert_input_dict(dataset)\n",
    "    G_multi, input_multi, output_multi = prune(d, G)\n",
    "    print(G_multi.shape, len(input_multi), len(output_multi))\n",
    "    all_v = input_multi.union(output_multi)\n",
    "    # Remove non reachable so error is 0 if reachable are fit\n",
    "    # as in carnival single\n",
    "    d2 = dict()\n",
    "    for k, v in d.items():\n",
    "        filtered_dict = {key: value for key, value in v.items() if key in all_v}\n",
    "        d2[k] = filtered_dict\n",
    "    d = d2\n",
    "    G_multi, input_multi, output_multi = prune(d, G) \n",
    "    # Clean non reachable vertices\n",
    "    G_pkn = create_flow_graph(G_multi, d)\n",
    "    P = signflow(\n",
    "        G_pkn,\n",
    "        d,\n",
    "        l0_penalty_edges = lambd\n",
    "    )\n",
    "    P.solve(solver=\"GUROBI\", IntegralityFocus=1, NoRelHeurTime=norel, Seed=seed, TimeLimit=max_time, verbosity=1)\n",
    "    valid_edges = set()\n",
    "    for i, (s, t) in enumerate(G_pkn.E):\n",
    "        s = list(s)\n",
    "        t = list(t)\n",
    "        if len(s)==1 and len(t)==1 and (not s[0].startswith(\"_\")) and (not t[0].startswith(\"_\")):\n",
    "            valid_edges.add(i)\n",
    "    all_edges_multi = np.zeros(G_pkn.shape[1])\n",
    "    sel_edges = np.zeros(G_pkn.shape[1])\n",
    "    E_multi = list(G_pkn.E)\n",
    "    scores = []\n",
    "    for i, (k, v) in enumerate(dataset.items()):\n",
    "        _, cp_inputs, cp_outputs = preprocess_graph(G_pkn, v[\"input\"], v[\"output\"])\n",
    "        s = score(G_pkn, P.expr[f\"edge_values_{k}\"].value, P.expr[f\"vertex_values_{k}\"].value, cp_inputs, cp_outputs)\n",
    "        scores.append(s)\n",
    "        sol_edges = np.flatnonzero(np.abs(P.expr[f\"edge_values_{k}\"].value) > 0)\n",
    "        all_edges_multi[sol_edges] += 1\n",
    "        sel_edges[sol_edges] = 1\n",
    "    return P, G_pkn, scores, all_edges_multi[list(valid_edges)]\n",
    "\n",
    "\n",
    "def multi_carnival_flow(G, dataset, acyclic_signal_version=True, acyclic_signal_name=\"v3\", excl_vertex_value=False, slack_reg=False, lambd=0.25, norel=0, max_time=600, solver=\"GUROBI\", seed=0):\n",
    "    d = convert_input_dict(dataset)\n",
    "    G_multi, input_multi, output_multi = prune(d, G)\n",
    "    print(G_multi.shape, len(input_multi), len(output_multi))\n",
    "    all_v = input_multi.union(output_multi)\n",
    "    exp_list = dict()\n",
    "    for k, v in dataset.items():\n",
    "        filtered_in = {key: value for key, value in v[\"input\"].items() if key in all_v}\n",
    "        filtered_out = {key: value for key, value in v[\"output\"].items() if key in all_v}\n",
    "        exp_list[k] = {\"input\": filtered_in, \"output\": filtered_out}\n",
    "        print(k, len(filtered_in), len(filtered_out))\n",
    "\n",
    "    G_exp_e = expand_graph_for_flows(G_multi, exp_list)\n",
    "    if acyclic_signal_version:\n",
    "        # v3 has L0 reg\n",
    "        if acyclic_signal_name == \"v3\":\n",
    "            P = create_flow_carnival_v3(G_exp_e, exp_list, lambd=lambd, exclusive_vertex_values=excl_vertex_value)\n",
    "        elif acyclic_signal_name == \"v4\":\n",
    "            P = create_flow_carnival_v4(G_exp_e, exp_list, lambd=lambd, slack_reg=slack_reg, upper_bound_flow=10, exclusive_vertex_values=excl_vertex_value)\n",
    "        else:\n",
    "            raise ValueError(acyclic_signal_name)\n",
    "    else:\n",
    "        P = create_flow_carnival(G_exp_e, exp_list, lambd=lambd)\n",
    "    if solver == \"GUROBI\":\n",
    "        P.solve(solver=solver, IntegralityFocus=1, NoRelHeurTime=norel, Seed=seed, TimeLimit=max_time, verbosity=1)\n",
    "    else:\n",
    "        P.solve(solver=solver, verbosity=1)\n",
    "    valid_edges = set()\n",
    "    for i, (s, t) in enumerate(G_exp_e.E):\n",
    "        s = list(s)\n",
    "        t = list(t)\n",
    "        if len(s)==1 and len(t)==1 and (not s[0].startswith(\"_\")) and (not t[0].startswith(\"_\")):\n",
    "            valid_edges.add(i)\n",
    "    all_edges_multi = np.zeros(G_exp_e.shape[1])\n",
    "    E_multi = list(G_pkn.E)\n",
    "    scores = []\n",
    "    for i, (k, v) in enumerate(dataset.items()):\n",
    "        _, cp_inputs, cp_outputs = preprocess_graph(G_exp_e, v[\"input\"], v[\"output\"])\n",
    "        s = score(G_exp_e, P.expr.edge_value.value[:,i], P.expr.vertex_value.value[:,i], cp_inputs, cp_outputs)\n",
    "        #_, cp_inputs, cp_outputs = preprocess_graph(G_pkn, exp_list[k][\"input\"], exp_list[k][\"output\"])\n",
    "        #s = score(G_pkn, P.expr[f\"edge_values_{k}\"].value, P.expr[f\"vertex_values_{k}\"].value, cp_inputs, cp_outputs)\n",
    "        scores.append(s)\n",
    "        all_edges_multi[np.flatnonzero(np.abs(P.expr.edge_value.value[:,i]) > 0)] += 1\n",
    "    return P, G_exp_e, scores, all_edges_multi[list(valid_edges)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29c80aa2-a263-4b81-ad55-ddfc5a45b461",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the input dict\n",
    "input_data = dict()\n",
    "for cell in selected_cells:\n",
    "    d = dict()\n",
    "    input_data[cell] = d\n",
    "    d[\"input\"] = targets\n",
    "    d[\"output\"] = get_measurements(cell, selected_drug)\n",
    "#input_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53414ad2-4de8-4b5e-b25e-b647780c2b59",
   "metadata": {},
   "outputs": [],
   "source": [
    "def summary(scores, edge_vector):\n",
    "    total = 0\n",
    "    edges = 0\n",
    "    for err, num_edges in scores:\n",
    "        total += err\n",
    "        edges += num_edges\n",
    "    diff_edges = np.sum(edge_vector > 0)\n",
    "    return total, diff_edges, diff_edges/edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78fb2a94-640a-48a6-a182-4dc71bffe0ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "P_fa, G_fa, scores_fa, edges_fa = multi_carnival_flow(G_pkn, input_data, solver=\"GUROBI\", acyclic_signal_version=True, excl_vertex_value=True, norel=300, lambd=0.01, acyclic_signal_name=\"v4\")\n",
    "for o in P_fa.objectives:\n",
    "    print(o.value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57016d72-f2e1-42d8-92c3-3e7954c1cd63",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
